{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/electricalengineer173/PIAIC1466-assigment-panda-part1-part2-/blob/main/Flowers_Recognition(PIAIC_77161).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXgJ6uT1NydQ"
   },
   "source": [
    "Assignment: Flowers Recognition <br>\n",
    "Dataset Description:<br>\n",
    "\n",
    "This dataset contains 4242 images of flowers.<br>\n",
    "The data collection is based on the data flicr, google images, yandex images.<br>\n",
    "You can use this datastet to recognize plants from the photo.<br>\n",
    "\n",
    "Attribute Information:<br>\n",
    "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
    "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
    "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
    "This is a Multiclass Classification Problem.<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vy-ktuOKJH"
   },
   "source": [
    "WORKFLOW : <br>\n",
    "Load Data <br>\n",
    "Split into 60 and 40 ratio.<br>\n",
    "Encode labels.<br>\n",
    "Create Model<br>\n",
    "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
    "Train the Model.<br>\n",
    "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
    "Prediction should be > 85%<br>\n",
    "Evaluation Step<br>\n",
    "Prediction<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri3Bg5qfPRic"
   },
   "source": [
    "Data : <br>\n",
    "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTtg3WuGTA1o"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYq1tLjMThy-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import join\n",
    "import cv2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEvOmCFZl8gd"
   },
   "outputs": [],
   "source": [
    "\n",
    "data = \"/content/drive/MyDrive/flowers/flowers\"\n",
    "\n",
    "# List out the directories inside the main input folder\n",
    "\n",
    "folders = os.listdir(data)\n",
    "\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ1mhV25Vy54"
   },
   "outputs": [],
   "source": [
    "# pictures loading and resizing\n",
    "image_names = []\n",
    "labels = []\n",
    "data_images = []\n",
    "\n",
    "\n",
    "size = 28,28\n",
    "\n",
    "for folder in folders:\n",
    "    for file in os.listdir(os.path.join(data,folder)):\n",
    "        if file.endswith(\"jpg\"):\n",
    "            image_names.append(os.path.join(data,folder,file))\n",
    "            labels.append(folder)\n",
    "            img = cv2.imread(os.path.join(data,folder,file))\n",
    "            im = cv2.resize(img,size)\n",
    "            data_images.append(im)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "korySXp3ik73"
   },
   "outputs": [],
   "source": [
    "# check length labels of pic\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNrswT8LyKFZ"
   },
   "outputs": [],
   "source": [
    "#check image length \n",
    "len(data_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ooes5VxJuK0H"
   },
   "outputs": [],
   "source": [
    "# label encoding\n",
    "label_dummies = pd.get_dummies(labels)\n",
    "\n",
    "labels =  label_dummies.values.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fu33GNFuuqlh"
   },
   "outputs": [],
   "source": [
    "# labels unique values\n",
    "pd.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Hgrb2oTxFdp"
   },
   "outputs": [],
   "source": [
    "# convet label and data into numpy array\n",
    "labels=np.asarray(labels).astype(\"float32\")\n",
    "data = np.asarray(data_images).astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0H8HafepZNR"
   },
   "outputs": [],
   "source": [
    "# lenght of images\n",
    "len(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfy7gF6FpYBv"
   },
   "outputs": [],
   "source": [
    "# length of label\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87wN0gKaybgB"
   },
   "outputs": [],
   "source": [
    "# shape of image and label\n",
    "print(f\"Shape of images is :{data.shape}\")\n",
    "print(f\"Shape of labels is :{labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjD3zNMDsSz-"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(data,labels,test_size=.40,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s511EsxqsuZB"
   },
   "outputs": [],
   "source": [
    "#shape of training data & testing data\n",
    "print(f\"Shape of training data is:{X_train.shape}\\nShape of testing data is :{X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7oGO6wJi-P3"
   },
   "outputs": [],
   "source": [
    "#shape of training & testing label\n",
    "print(f\"Shape of training labels is:{y_train.shape}\\nShape of testing labels is :{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Syu2FZIckr5q"
   },
   "outputs": [],
   "source": [
    "# Check first image of Training data\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rz_xZCv7WNtm"
   },
   "outputs": [],
   "source": [
    "#check first labels of training image\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mm7WYHSxYO4g"
   },
   "outputs": [],
   "source": [
    "# model buiding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Flatten,Dense\n",
    "\n",
    "network =Sequential()\n",
    "network.add(Conv2D(8, (1,1),input_shape=(28, 28, 3),activation='relu'))\n",
    "network.add(MaxPool2D(pool_size=(1,1)))\n",
    "network.add(Conv2D(16, (1,1),activation='relu'))\n",
    "network.add(MaxPool2D(pool_size=(2,2)))\n",
    "network.add(Flatten())\n",
    "network.add(Dense(128,activation='relu'))\n",
    "network.add(Dense(10,activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "et64nng0deu4"
   },
   "outputs": [],
   "source": [
    "#model summary\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npGn6x2RiJVL"
   },
   "outputs": [],
   "source": [
    "#model compiling\n",
    "network.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "py_P71wz2dZ1"
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 20\n",
    "history=network.fit(X_train, y_train,batch_size=batch_size,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kULnJgXx2mjj"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "[u'accuracy', u'loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOIHV6GZ3Lnb"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_accuracy = history_dict['accuracy']\n",
    "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
    "plt.plot(epochs, loss_values, 'r', label='loss')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='accuracy')\n",
    "plt.title('loss and accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgXa5W3480Wz"
   },
   "outputs": [],
   "source": [
    "network.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQajCO4u9DZt"
   },
   "outputs": [],
   "source": [
    "pred = network.predict_classes(X_test[:10])\n",
    "for i in range(len(pred)):\n",
    "    print(pred[i],'==>',y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAQHamBp_xG6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1, 2, 1 )\n",
    "plt.hist(y_test[:10])\n",
    "plt.xlabel('original target value')\n",
    "plt.ylabel('count')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(pred)\n",
    "plt.xlabel('aggregated target value')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Flowers_Recognition(PIAIC 77161).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
